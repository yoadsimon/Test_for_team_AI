import os
from typing import List, Optional, Dict, Any
import google.generativeai as genai
from dataclasses import dataclass
from dotenv import load_dotenv
import logging
from pydantic import BaseModel, Field

# LangChain imports
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser
from langchain.memory import ConversationBufferMemory
from langchain_core.output_parsers import StrOutputParser


@dataclass
class HighlightDescription:
    """Description of a video highlight generated by the LLM."""
    timestamp: float
    description: str
    summary: Optional[str] = None
    importance_score: Optional[int] = None
    category: Optional[str] = None


class HighlightOutput(BaseModel):
    """Structured output for highlight generation."""
    is_highlight: bool = Field(description="Whether this moment deserves to be a highlight")
    importance_score: int = Field(description="Importance score from 1-10")
    description: str = Field(description="Clear, engaging description of what's happening")
    category: str = Field(description="Category: action, dialogue, scene_change, key_moment, or other")
    summary: str = Field(description="One-sentence summary of the significance")


class LLMService:
    """Enhanced LLM service using LangChain for intelligent highlight extraction."""

    def __init__(self):
        """Initialize the enhanced LLM service with LangChain."""
        # Load environment variables
        load_dotenv()
        
        # Get API key from environment
        self.api_key = os.getenv("GOOGLE_API_KEY")
        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY not found in environment variables. Please add it to your .env file.")
        
        try:
            # Configure the Gemini API
            genai.configure(api_key=self.api_key)
            
            # Initialize LangChain LLM
            self.llm = ChatGoogleGenerativeAI(
                model="gemini-1.5-flash",
                google_api_key=self.api_key,
                temperature=0.7
            )
            
            # Initialize the embedding model
            self.embedding_model = GoogleGenerativeAIEmbeddings(
                model="models/embedding-001",
                google_api_key=self.api_key,
                task_type="retrieval_document"
            )
            
            # Set up output parser
            self.output_parser = PydanticOutputParser(pydantic_object=HighlightOutput)
            
            # Set up structured prompts
            self._setup_prompts()
            
            # Set up chains
            self._setup_chains()

            # Set up logging
            self.logger = logging.getLogger(__name__)
            self.logger.info("Enhanced LLM service with LangChain initialized successfully")
            
        except Exception as e:
            raise RuntimeError(f"Failed to initialize services: {str(e)}")

    def _setup_prompts(self):
        """Set up structured prompts for different tasks."""
        
        # Highlight filtering and generation prompt
        self.highlight_prompt = PromptTemplate(
            input_variables=["audio_text", "timestamp", "video_context"],
            template="""You are an expert video content analyst. Analyze this moment from a video:

TIMESTAMP: {timestamp:.1f} seconds
AUDIO: "{audio_text}"
VIDEO CONTEXT: {video_context}

Determine if this moment should be a highlight. Good highlights include:
- Important dialogue or key information
- Significant actions or events
- Scene transitions or dramatic moments
- Educational or informative content
- Emotional or engaging moments

Avoid highlighting:
- Filler words or casual conversation
- Long pauses or silence
- Repetitive content
- Low-value chatter

{format_instructions}

Provide your analysis:""",
            partial_variables={"format_instructions": self.output_parser.get_format_instructions()}
        )
        
        # Summary generation prompt
        self.summary_prompt = PromptTemplate(
            input_variables=["highlights"],
            template="""You are summarizing a video based on its key highlights. Here are the important moments:

{highlights}

Create a concise but informative summary that:
1. Captures the main narrative or key points
2. Highlights the most important moments
3. Explains the overall context and significance
4. Uses engaging, natural language
5. Is 2-3 sentences long

Summary:"""
        )

    def _setup_chains(self):
        """Set up modern LangChain chains using Runnable interface."""
        
        # Modern highlight generation chain using pipe operator
        self.highlight_chain = self.highlight_prompt | self.llm | self.output_parser
        
        # Modern summary generation chain using pipe operator  
        self.summary_chain = self.summary_prompt | self.llm | StrOutputParser()

    def generate_highlight_description(
        self,
        audio_context: str,
        timestamp: float,
        video_context: str = "General video content"
    ) -> Optional[HighlightDescription]:
        """
        Generate a highlight description using smart filtering and structured output.
        
        Args:
            audio_context: Transcribed audio text
            timestamp: Timestamp in seconds
            video_context: Brief context about the video content
            
        Returns:
            HighlightDescription if moment is significant, None otherwise
        """
        try:
            # Use modern LangChain Runnable chain - this directly returns a HighlightOutput object
            result = self.highlight_chain.invoke({
                "audio_text": audio_context,
                "timestamp": timestamp,
                "video_context": video_context
            })
            
            # The modern chain with output_parser directly returns a HighlightOutput object
            # Only create highlight if the AI determines it's significant
            if result.is_highlight and result.importance_score >= 6:  # Threshold for quality
                return HighlightDescription(
                    timestamp=timestamp,
                    description=result.description,
                    summary=result.summary,
                    importance_score=result.importance_score,
                    category=result.category
                )
            
            return None  # Not significant enough to be a highlight
            
        except Exception as e:
            self.logger.error(f"Error generating highlight description: {e}")
            # Fallback to simple description
            return HighlightDescription(
                timestamp=timestamp,
                description=f"Video moment with audio: {audio_context[:100]}...",
                summary="Video content",
                importance_score=5
            )

    def generate_highlight_summary(
        self, highlights: List[HighlightDescription]
    ) -> str:
        """
        Generate a summary of multiple highlights using LangChain.
        
        Args:
            highlights: List of highlight descriptions
            
        Returns:
            Summary of the highlights
        """
        if not highlights:
            return "No significant highlights found in this video."

        # Prepare highlights for summary
        highlights_text = "\n".join([
            f"â€¢ At {h.timestamp:.1f}s: {h.description} (Score: {h.importance_score or 'N/A'})"
            for h in highlights
        ])

        try:
            # Use modern LangChain Runnable chain - this directly returns a string
            summary = self.summary_chain.invoke({"highlights": highlights_text})
            return summary.strip()
        except Exception as e:
            self.logger.error(f"Error generating summary: {e}")
            return f"Video contains {len(highlights)} key highlights covering various important moments."

    def generate_embedding(self, text: str) -> List[float]:
        """
        Generate embedding for text using Google's embedding model.
        
        Args:
            text: Text to generate embedding for
            
        Returns:
            List of embedding values
        """
        try:
            embedding = self.embedding_model.embed_query(text)
            return embedding
        except Exception as e:
            self.logger.error(f"Error generating embedding: {e}")
            # Return a zero vector as fallback
            return [0.0] * 768  # Standard embedding dimension

    def batch_generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        Generate embeddings for multiple texts efficiently.
        
        Args:
            texts: List of texts to generate embeddings for
            
        Returns:
            List of embedding vectors
        """
        try:
            embeddings = self.embedding_model.embed_documents(texts)
            return embeddings
        except Exception as e:
            self.logger.error(f"Error generating batch embeddings: {e}")
            # Return zero vectors as fallback
            return [[0.0] * 768] * len(texts) 